source("../shapley-permutation-opt.dml") as shapleyPermutation
source("../shapley-permutation.dml") as shapleyPermutationLegacy
source("../shapley-utils.dml") as shapleyUtils

#load data

X_bg_path=ifdef($X_bg_path, "../data/census/census_xTest.bin")
X_bg = read(X_bg_path)
B_path=ifdef($B_path, "../data/census/census_bias.csv")
B = read(B_path)

# you set the total number of permutations from the commandline using `-nvargs n_permutations=10`
n_permutations = ifdef($n_permutations, 10)
# you set the total number of integration_samples from the commandline using `-nvargs integration_samples=100`
integration_samples = ifdef($integration_samples, 10)
execution_policy = ifdef($execution_policy, "auto")
# you set the total number of rows from the commandline using `-nvargs rows_to_explain=10`
rows_to_explain = ifdef($rows_to_explain, 10)
# set remove_non_var
remove_non_var = ifdef($remove_non_var, 0)
# use partitions
use_partitions = ifdef($use_partitions, 0)
if (use_partitions == 1){
  metadata_path=ifdef($metadata_path, "../data/census/census_dummycoding_meta.csv")
  metadata = read(metadata_path)
  partitions=shapleyUtils::meatadataToPartitions(metadata=metadata)
} else {
  partitions = as.matrix(-1)
}

print("Computing shapley values for "+rows_to_explain+" rows with "+n_permutations+" permutatitons, "+integration_samples+" samples to marginalise masked features.")
print("Keep in mind that shap values for raw svm outputs is harder to interpret than probabilities.")

#select instances to compute shapley values for
x = X_bg[1:rows_to_explain,]

#compute shapley values
if(execution_policy != 'legacy-iterative'){
  [S, expected] = shapleyPermutation::shapley_permutation_explainer(
    model_function="shap_l2svmPredict_custom",
    model_args=list(B=B),
    x=x,
    X_bg=X_bg,
    n_permutations=n_permutations,
    integration_samples=integration_samples,
    desired_max_batch_size=-1,
    execution_policy=execution_policy,
    remove_non_var=remove_non_var,
    partitions=partitions,
    seed=-1,
    verbose=1
  )
} else {
  print("Using iterative legacy approach.")
  S = matrix(0, rows=nrow(x), cols=ncol(x))
  expected = matrix(0, rows=nrow(x), cols=1)
  parfor (i in 1:nrow(x), check=0){
    [phis, e] = shapleyPermutationLegacy::shapley_permutations(
      model_function="shap_l2svmPredict_custom",
      model_args=list(B=B),
      x=x[i],
      X_bg=X_bg,
      n_permutations=n_permutations,
      integration_samples=integration_samples,
      seed=-1,
      verbose=0
    )
    S[i] = phis
    expected[i] = e
  }
  expected = mean(expected)
}

print("Expected: "+toString(expected))
print("Resulting phis rowsum:\n"+toString(rowSums(S)))


#transpose it to make it fit the representation of values in the SHAP python package
S = t(S)
# write values to csv
write_to_file = ifdef($write_to_file, 1)
if( write_to_file == 1){
  #custom tag for results
  file_tag = ifdef($file_tag, "")
  print("Writing to file")
  write(S, "../data/census/shap_values_permutation_"+n_permutations+"perm_"+integration_samples+"samples"+file_tag+".csv", format="csv")
}

# function to wrap multiLogRegPredict to make sure its outputs are compatible
shap_l2svmPredict_custom = function(Matrix[Double] X, Matrix[Double] B)
  return( Matrix[Double] P){
  [P, n] = l2svmPredict(X=X, W=B, verbose=FALSE)
}
